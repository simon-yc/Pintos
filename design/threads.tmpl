            +--------------------+
            | CSCC69             |
            | PROJECT 1: THREADS |
            | DESIGN DOCUMENT    |
            +--------------------+
   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Meiyi Xie <flora.xie@mail.utoronto.com>
Linda Shi <lindashi.shi@mail.utoronto.ca>
Simon Chau <simon.chau@mail.utoronto.ca>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             ALARM CLOCK
             ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    /* Initialized to 0. Each thread keeps track of its wakeup time */
    
    int64_t wakeup_time;

Added static struct list:

    /* List of sleeping threads sorted in ascending order of wakeup time */

    static struct list sleeping_list;   /* List of sleeping threads */

Added to struct thread:

    struct list_elem sleepelem;         /* List element for sleeping threads. */

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Originally, timer-sleep() used busy wait. This never puts the thread 
to sleep, rather, the current thread is in a while loop and simply
gets pushed to the back of the ready queue. This is a waste of resources
to have this constantly running.

In our new implementation, we make it more efficient by blocking it 
until the thread's sleeping time finishes. This way, we save valuable
CPU storage. Every time the timer interrupt handler runs, the global 
variable ticks increases by 1, it also checks each thread and decrease 
the wakeup_time of each sleeping thread by 1. If wakeup_time of the thread 
is less than or equal to the global variable ticks, then move the thread back 
to the ready list by unblocking it.

To outline to the steps:

In a call to timer_sleep()
1. check if the ticks non-negative
2. disable interrupt
3. call insert_sleeping_list
    3.1. insert the thread into the sleeping list
    3.2. block the thread
4. enable interrupt
 
In a call to timer interrupt handler
1. increment global variable ticks
2. call thread_tick
    2.2. iterate through sleeping list, remove and unblock threads that
       have wakeup_time <= ticks

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

We create a list for sleeping threads in thread.c to keep track of all 
the threads that are currently in sleep. Each time we want to check if any
threads needs to wake up (and  moved to the ready list), we can simply iterate 
through the sleeping list. This is more efficient because we only
need to check the threads that are sleeping, rather than all of the threads.
Furthermore, we keep the sleeping list in ascending order of wake time, so
that we can stop checking once we encounter a thread with greater wake up time
than current ticks. This minimizes the time spent in the timer interrupt handler
because we only deal with the sleeping thread and we only need to perform a 
minimal amount of checks to wake up threads.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Race conditions are avoided by temporarily disabling interrupts. Our algorithm 
diable interrputs before call insert_sleeping_list(). When multiple threads call 
timer_sleep() simultaneously, only one thread can access the sleeping_list, so
no two threads  can modify sleeping_list the same time. 

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Race conditions are avoided by temporarily disabling interrupts. Our 
algorithm saves wake up time in sleeping_list, each time defore we call 
insert_sleeping_list() in timer_sleep(), we disable interrupts, so no time 
interrupt can occur during insert_sleeping_list(). Wake up time can be 
correctly stored into sleeping_list.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because it is much more efficient than the original. We
had considered using a sleeping list with each thread keeping track of its
remaining sleeping time. However, this would require us to iterate through
the sleeping list every time the timer interrupt handler runs, which would
be inefficient. Our design is superior because we only need to iterate through
the sleeping list for the threads that need to wake up.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

   /* Will hold thread's original priority, so after the priority 
      donation finishes, thread is able to get back its actual 
      priority. */
    int ori_priority;

    /* Keep tract of the list of locks the thread is holding. */
    struct list locks_holding;

    /* The lock that the thread is trying to acquire, or the lock 
       that locks the thread */
    struct lock *lock;

Added to struct lock:

    /* List element for lock */
    struct list_elem lock_elem;

    /* Maximum priority within all threads trying to acquire this lock. */
    int max_priority;

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

The data structure that we used to track priority donation are extra fields
we added to the thread and lock structs.

In the thread struct, we added 
ori_priority to keep track of the original threads priority in the case that
the thread inherits the priority of another thread. We also have each thread
keep track of the lock it is trying to acquire. In other words, the lock that
the thread is waiting for. Finally, each thread maintains locks_holding which
as the name suggests, is a list of the locks that the thread is holding.

In the lock struct, we added
lock_elem is a list_elem for the list locks_holding that each thread has. To 
keep track of the maximum priority of the out of all the threads that want 
to acquire this lock.

thread A lock thread B t

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
Threads waiting for a lock, semaphore, or condition variable will wake up once 
the lock is released. When the lock is released, the semaphore will go up. By 
our implementation, everytime as semaphore goes up, it will sort its waiters list 
so the first thread has the highest priority among all the waiters. Therefore, 
each time the semaphore is released, as our implementation choosees to unblock 
the first thread in the waiters list, the highest priority thread waiting will 
be wake up first, as wanted.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
1. Go to step 6 if currently there is not a holder for the lock. 
   Else if there is a holder for the lock:
2. Set the thread's lock to this lock so it is locked by this lock. 
3. If the current thread has a higher priority than the highest priority among 
   all other threads holding this lock, set this lock's maximum priority to 
   current thread's priority. 
4. Do priority donation to the lock's holder thread H so it can run first: 
   4.1. Get the max priority between the H's original priority and the 
        highest priority among all threads that are locked by locks that H holds 
        (which includes current thread's priority since the it is currently locked 
        by locks that H holds). 
   4.2. Set H's priority to the above max priority. 
   4.3. As H should now have a higher priority, sort the ready list so H can get run. 
5. Let the l be the lock that is locking the holder thread if there exist such l, then 
   go back to step 3. If such l does not exist, go to step 6
6. While the semaphore value is 0, add the current thread to the lock's waiters and 
   block it. 
7. Once the semaphore value is not 0, decrease it by one. 
8. Now the current thread should hold this lock. Turn off the interruption.
9. Set the lock's max priority to current thread's priority. 
10. Add the lock to the locks holding list of the current thread in descending order 
    of each lock's max priority. 
11. 

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
1. If thread is mlfqs, go to step 5 else:
2. Turn off the interruption while updating the lock and its holder, remove the 
   lock elements from the lock_holding list of the thread that is holding it.
3. Update the old lock holder thread's priority as it just released a lock.
4. Turn on the interruption.
5. Set the lock's new holder to NULL.
6. Turn off the interruption.
7. If the list of waiters is not empty, sort the list of waiters in descending 
   order of their priority. Pop out from this list and unblock the thread with 
   the highest priority. 
8. Increase the semaphore value by one, and turn on the interruption
9. Run thread yield to allow the highest priority thread run, as some thread's 
   priority may have been changed after this lock got released.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Suppose thread A has priorty 5 called thread_set_priority(). Now its just 
before the line to set its own priority to 10, and thread switching happens.
There is another thread B with priority 20 who just got locked by thread A so 
it will donate its priority to thread A. This thread B updated thread A's
priority to 20. Now thread switching happens again, thread A set its priorty
to 10 which is incorrect.

Our implementation disabled interrput in thread_set_priority(), so no thread
switching can happen during thread_set_priority(). This race condition is 
prevented.

I don't think use a lock can avoid this race. If add a lock to
thread_set_priority(), it cannot prevent other threads from accessing
thread A's priority.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

In the Pintos operating system, the priority scheduling design was chosen 
because it is a simple and effective way to manage the scheduling of threads. 
The design prioritizes threads based on their priority, giving higher-priority 
threads preference over lower-priority threads. This ensures that important 
tasks are executed quickly, reducing the risk of starvation for high-priority 
threads.One advantage of this design is that it is easy to understand and 
implement. The priority scheduling algorithm is straightforward and does not 
require complex calculations or data structures. This makes it easier to 
maintain and debug the scheduling code.Another advantage of priority 
scheduling is that it is more predictable and deterministic than other 
scheduling algorithms. The priority of each thread is well-defined, and the 
scheduling order is determined by the priority of each thread. This makes it 
easier to debug and diagnose performance issues, as the order of execution is 
known in advance.It is possible that another design, such as a round-robin 
scheduling algorithm, could be superior in some situations. For example, round-
robin scheduling can help ensure that each thread gets a fair share of CPU 
time, even if some threads have a lower priority. However, in a Pintos system 
with relatively simple scheduling requirements, priority scheduling is likely 
to be the most appropriate design choice.

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.



---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
